{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introudction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian approach is a different statistical school of inference than the frequentist approach. The Bayesian approach starts with a prior belief about a parameter of interest and then updates that belief as more data is collected. Such an approach is well suited for sequential test settings. \n",
    "  \n",
    "Here we focus on how to use the Bayesian approach for conversion rate A/B tests. It can be easily extended to other metrics. Data from conversion rate tests can be modeled as a binomial sequence with parameter $p$. The beta distribution is a convenient distribution for modeling a binomial parameter $p$. A user's prior belief about the probability distribution of parameter $p$ can be expressed as $Beta\\left(a, b\\right)$. After $N$ samples with $S$ successes are collected from the test, the updated belief about $p$ can be expressed by a posterior probability distribution. Using Bayes theorem, it can be proved that this posterior probability distribution for $p$ equals to $Beta\\left(S+a,N-S+b\\right)$. Therefore, throughout the test, we only need to keep track of 2 numbers, $N$ and $S$, to update the posterior probability distribution of $p$ for a binomial data sequence.\n",
    "\n",
    "Once we can derive the probability distributions for parameters, we can easily compute many useful statistics. For example, we can compute the probability that the variant $A$ is better than the variant $B$ using the joint probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X:\\,Random\\,variable\\,for\\:conversion\\,rate\\,of\\,variant\\,A\\,$$\n",
    "$$\\,Y:\\,Random\\,variable\\,for\\,conversion\\,rate\\,of\\,variant\\,B$$\n",
    "\n",
    "$$X\\sim Beta\\left(a,b\\right),Y\\sim Beta\\left(c,d\\right)$$\n",
    "\n",
    "$$P\\left(X>Y\\right)= \\int_0^1\\int_y^1 \\frac{x^a\\left(1-x\\right)^b}{B\\left(a,b\\right)} \\frac{y^c\\left(1-y\\right)^d}{B\\left(c,d\\right)}~dx~dy \n",
    "\\equiv g\\left(a, b, c, d\\right)\n",
    "= \\frac{\\Gamma\\left(d+b\\right)\\Gamma\\left(d+c\\right)}{\\Gamma\\left(d+b+c\\right)\\Gamma\\left(d\\right)} + \\sum_{i=1}^{a-1} \\left(\\frac{\\Gamma\\left(i+c\\right)\\Gamma\\left(b+d\\right)\\Gamma\\left(i+b\\right)\\Gamma\\left(c+d\\right)}{\\Gamma\\left(i\\right)\\Gamma\\left(b\\right)\\Gamma\\left(c\\right)\\Gamma\\left(d\\right)\\Gamma\\left(i+b+c+d\\right)}\\right) / i$$\n",
    "   \n",
    "$$B\\left(a, b\\right)\\,is\\,the\\,beta\\,fuction\\,with\\,parameters\\,a\\,and\\,b$$\n",
    "$$\\Gamma\\left(a\\right)\\,is\\,the\\,gamma\\,fuction\\,with\\,parameter\\,a$$\n",
    "   \n",
    "Note:  The derivation of the above closed-form formula can be found [here](https://www.johndcook.com/UTMDABTR-005-05.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Testing\n",
    "\n",
    "We also can design a decision rule based on posterior distributions to continuously monitor test results and conclude a test whenever a significant effect is present. Expected loss and ROPE methods are two of such decision rules.\n",
    "\n",
    "## Expected Loss Method\n",
    "It is based on the loss function and expected loss as defined below. Expected loss represents the expected losses associated with choosing \"A\" or \"B\" as the winner.[1]\n",
    "\n",
    "### Loss function:\n",
    "  \n",
    "$L_x=max\\left(Y-X, 0\\right),L_y=max\\left(X-Y, 0\\right)$\n",
    "\n",
    "### Expected loss:\n",
    "\n",
    "$$E[L_x] = \\int_0^1\\int_0^1 max\\left(y-x,0\\right)\\frac{x^a\\left(1-x\\right)^b}{B\\left(a,b\\right)} \\frac{y^c\\left(1-y\\right)^d}{B\\left(c,d\\right)}~dx~dy\n",
    "= \\frac{B\\left(c+1,d\\right)}{B\\left(c,d\\right)}g\\left(c+1,d,a,b\\right) - \n",
    "\\frac{B\\left(a+1,b\\right)}{B\\left(a,b\\right)}g\\left(c,d,a+1,b\\right)$$\n",
    "\n",
    "$$E[L_y] = \\int_0^1\\int_0^1 max\\left(x-y,0\\right)\\frac{x^a\\left(1-x\\right)^b}{B\\left(a,b\\right)} \\frac{y^c\\left(1-y\\right)^d}{B\\left(c,d\\right)}~dx~dy\n",
    "= \\frac{B\\left(a+1,b\\right)}{B\\left(a,b\\right)}g\\left(a+1,b,c,d\\right) - \n",
    "\\frac{B\\left(c+1,d\\right)}{B\\left(c,d\\right)}g\\left(a,b,c+1,d\\right)$$\n",
    "  \n",
    "  \n",
    "Note: the derivation of the above closed-form formula can be found [here](https://www.chrisstucchio.com/blog/2014/bayesian_ab_decision_rule.html).\n",
    "\n",
    "### Decision rule:  \n",
    "  \n",
    "Chose a threshold of caring($toc$). If the expected loss of a variant is below $toc$, then declare this variant as the winner. \n",
    "\n",
    "\n",
    "## ROPE Method\n",
    "\n",
    "Let $\\mu_A$ represent the posterior distribution of the conversion rate of variant A and $\\mu_B$ represent the posterior distribution of the conversion rate of variant B. $\\mu_B - \\mu_A$ represents the posterior distribution of the lift(treatment effect) of variant B over variant A. 95% HDI is defined as the shortest interval covering 95% posterior density of $\\mu_B - \\mu_A$. ROPE is an interval with 0 as its center and defined based on the minimum detectable effect(MDE) specified prior to the start of a test. The ROPE decision rule uses 95% HDI and ROPE jointly to decide test outcomes.[2]\n",
    "\n",
    "### Decision rule:  \n",
    "\n",
    "This decision rule is illustrated by the following 4 scenarios.\n",
    "\n",
    "Case (a), the 95% HDI is completely outside of the ROPE, on the right hand side of the ROPE.\n",
    "The test is considered conclusive and variant B is declared as the winner.  \n",
    "\n",
    "Case (b), the 95% HDI is completely outside of the ROPE, on the left hand side of the ROPE.\n",
    "The test is considered conclusive and variant A is declared as the winner.  \n",
    "\n",
    "Case (c), the 95% HDI is completely inside the ROPE. \n",
    "The test is considered conclusive and variants A and B are considered to be effectively equivalent.  \n",
    "\n",
    "Case (d), the 95% HDI overlaps with the ROPE and the test is considered inconclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] C. Stucchio, Bayesian A/B Testing at VWO, Whitepaper, Visual Website Optimizer, 2015.   \n",
    "[2] J.K. Kruschke, Bayesian estimation supersedes the t test, J. Exp. Psychol. Gen. 142, 573â€“603, 2013."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
